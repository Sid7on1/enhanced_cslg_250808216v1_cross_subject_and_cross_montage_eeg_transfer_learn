{
  "agent_id": "coder2",
  "task_id": "task_6",
  "files": [
    {
      "name": "augmentation.py",
      "purpose": "Data augmentation techniques",
      "priority": "medium"
    },
    {
      "name": "feature_extraction.py",
      "purpose": "Feature extraction layers",
      "priority": "medium"
    }
  ],
  "project_info": {
    "project_name": "enhanced_cs.LG_2508.08216v1_Cross_Subject_and_Cross_Montage_EEG_Transfer_Learn",
    "project_type": "computer_vision",
    "description": "Enhanced AI project based on cs.LG_2508.08216v1_Cross-Subject-and-Cross-Montage-EEG-Transfer-Learn with content analysis. Detected project type: computer vision (confidence score: 7 matches).",
    "key_algorithms": [
      "Crowdsourcing",
      "Parallel",
      "Improve",
      "Geometry",
      "Machine",
      "Pre-Trained",
      "Combined",
      "Auditory",
      "Transfer",
      "Unified"
    ],
    "main_libraries": [
      "torch",
      "numpy",
      "pandas"
    ]
  },
  "paper_content": "PDF: cs.LG_2508.08216v1_Cross-Subject-and-Cross-Montage-EEG-Transfer-Learn.pdf\nChunk: 1/1\n==================================================\n\n--- Page 1 ---\nJOURNAL OF XXXX, VOL. X, NO. X, XX XXXX 1\nCross-Subject and Cross-Montage EEG Transfer\nLearning via Individual Tangent Space Alignment\nand Spatial-Riemannian Feature Fusion\nNicole Lai-Tan, Xiao Gu, Marios G. Philliastides, Fani Deligianni\nAbstract \u2014Personalised music-based interventions offer a pow-\nerful means of supporting motor rehabilitation by dynamically\ntailoring auditory stimuli to provide external timekeeping cues,\nmodulate affective states, and stabilise gait patterns. Gener-\nalisable Brain-Computer Interfaces (BCIs) thus hold promise\nfor adapting these interventions across individuals. However,\ninter-subject variability in EEG signals, further compounded\nby movement-induced artefacts and motor planning differences,\nhinders the generalisability of BCIs and results in lengthy\ncalibration processes. We propose Individual Tangent Space\nAlignment (ITSA), a novel pre-alignment strategy incorporating\nsubject-specific recentering, distribution matching, and super-\nvised rotational alignment to enhance cross-subject general-\nisation. Our hybrid architecture fuses Regularised Common\nSpatial Patterns (RCSP) with Riemannian geometry in parallel\nand sequential configurations, improving class separability while\nmaintaining the geometric structure of covariance matrices\nfor robust statistical computation. Using leave-one-subject-out\ncross-validation, \u2018ITSA\u2019 demonstrates significant performance\nimprovements across subjects and conditions. The parallel fusion\napproach shows the greatest enhancement over its sequential\ncounterpart, with robust performance maintained across varying\ndata conditions and electrode configurations. The code will be\nmade publicly available at the time of publication.\nIndex Terms \u2014EEG-based BCIs, Music-based gait rehabil-\nitation, Sensorimotor Entrainment, Rhythmic cueing, Cross-\nsubject variability, Transfer learning, Pre-alignment strategies,\nRegularised common spatial patterns, Riemannian Geometry\nI. I NTRODUCTION\nBrain-computer interfaces (BCI) are effective tools for mo-\ntor rehabilitation and understanding musical stimulus effects\non motor function [1]\u2013[4]. In stroke rehabilitation, BCIs\ndecode the user\u2019s intention from brain electrical activity to\nprovide sensorimotor feedback and enable control of external\ndevices or motor functions [5], [6]. The use of these BCI\nstrategies for motor rehabilitation has been grouped into either\nassistive or rehabilitative. The former focuses on bypassing the\ndamaged neuronal pathways to provide alternative control of\nthe external devices, whereas the latter aims to exploit neuro-\nplasticity by promoting the recovery of damaged pathways and\ntherefore restoring impaired motor functions [5]. Electroen-\ncephalography signals are often used for the input of BCIs\nas they provide portable, non-invasive, low-cost solutions and\nhave high temporal resolution [7].\nWe\u2019d like to acknowledge funding from UKRI Centre for Doctoral\nTraining in Socially Intelligent Artificial Agents, (EP/S02266X/1), EPSRC\n(EP/W01212X/1) and Academy of Medical Sciences (NGR1/1678).\nManuscript received XX XX XXXX; revised XX XX XXXX.Integrating musical stimulus with rehabilitative EEG-based\nBCI for gait rehabilitation presents a novel approach to\nbridge between motor recovery, emotional regulation and user\nengagement. While auditory-feedback BCIs remain under-\nexamined compared to visual counterparts [8], musical stim-\nulus offers potential advantages as it guides users for goal-\noriented behaviour and it also emotionally engages them, pro-\nmoting consistent participation and enhancing neuroplasticity\n[4], [5], [8], [9]. Towards this end, mixed-reality musical\nexercise, featuring holographic targets synchronised to music,\nresulted in increased hip and knee flexion in stroke patients\n[9]. Despite promising results in improving motor function and\nreducing risks of falls [3], [10], [11], integration of musical\nand auditory-cued interventions with BCI systems as a closed-\nloop gait rehabilitation remains limited.\nA considerable challenge in EEG-based BCIs is cross-\nsubject generalisation, where models trained on one population\nmust perform on entirely unseen individuals [6], [12]\u2013[15].\nVariability results from anatomical differences, electrode po-\nsition shifts between sessions and inter-subject variations in\nbrain functions [12], [14].Additionally, auditory gait rehabili-\ntation involves subjects in motion, which introduces movement\nartifacts and muscle activity that compromise EEG signal\nquality. Yet the sensitivity of BCIs to these motion-induced\ndisturbances remains largely unexplored. This necessitates\ntime-consuming calibration processes for new user making\nreal-world deployment impractical [12], [16].\nTo compensate for these inter-subject variability and con-\nsequent covariate shifts between training and testing feature\ndistribution, transfer learning (TF) techniques have been pro-\nposed [12]. TF seeks to leverage known information from\nprevious sessions and past participants - the source dataset, to\nimprove upon unseen samples of subjects - target dataset [13],\n[14]. Pre-alignment strategies (PS) are crucial for optimising\nTF from the source to target domain [6]. However, current\npre-alignment strategies face several critical limitations. First,\nmany approaches perform alignment in Euclidean space and\nignore the inherent geometric and curvature structure of co-\nvariance matrices that naturally lie on Riemannian manifolds\n[13]. Second, existing methods often applies global align-\nment strategies that do not account for individual subject\ncharacteristics adequately [14], potentially leading to over-\nregularisation or insufficient adaptation that could be addressed\nwith the integration of individual adaptation [17]. Third, they\nfocus on reducing variability across datasets to account for the\nlimited available training data [6] and typically ignore cross-arXiv:2508.08216v1  [cs.LG]  11 Aug 2025\n\n--- Page 2 ---\nJOURNAL OF XXXX, VOL. X, NO. X, XX XXXX 2\ndomain scenarios with different channel configurations, such\nas training on high-density EEG data and testing on a portable\nsystem with fewer channels.\nFurthermore, the integration of spatial filtering techniques\nwith geometric alignment methods remains underexplored,\ndespite their complementary nature. Common Spatial Patterns\n(CSP) excel at maximising class separability [18], while\nRiemannian geometry-based methods preserve the statistical\nstructure of covariance matrices [19]. As such, fusion of\nCSP and Riemannian approaches could enable greater inter-\npretability via spatial projections that reveal how discrimi-\nnative features relate to neurophysiological processes, while\nalso preserving the underlying covariant structure captured by\nRiemannian geometry.\nIn this work, we address these challenges by proposing Indi-\nvidual Tangent Space Alignment (ITSA) , a novel pre-alignment\nstrategy specifically designed to mitigate inter-subject variabil-\nity in leave-one-subject-out (LOSO) classification scenarios.\nOur approach incorporates three key innovations: (1) subject-\nspecific recentering that individually aligns each subject\u2019s\ncovariance matrices, (2) distribution matching through feature\nrescaling, and (3) supervised rotational alignment with robust\ncalibration procedures. Additionally, we build on previous\nworks [20] to introduce a hybrid feature extraction architecture\nthat fuses Regularised Common Spatial Patterns (RCSP) with\nRiemannian geometry techniques in both sequential and paral-\nlel configurations. In the sequential approach, spatial filtering\nis applied to the signals first, followed by a tangent space\nprojection to extract features. In contrast, the parallel approach\nindependently derives the (1) features from spatially filtered\nsignals and (2) features from the tangent space projection, and\nthen concatenates them. This fusion approach aims to max-\nimise class separability by enhancing discriminative features\nwhile simultaneously preserving the geometric structure of\ncovariance matrices for more accurate statistical computations.\nWe explore cross-domain variability arising from differing\nEEG electrode configurations between training and testing\ndatasets, training on high-density and testing on simulated low-\ndensity electrode montages.\nOur evaluation framework employs rigorous leave-one-\nsubject-out cross-validation with statistical validation, abla-\ntion studies, and interpretability analyses. Results demon-\nstrate superior performance with \u2018ITSA\u2019 and parallel RCSP-\nRiemannian fusion.\nSection II presents the related work, Section III briefly\nintroduces notation, Section V describes the mathematical\nbackground and methodology for our proposed pre-alignment\nstrategy and feature extraction methods, Section VII presents\nperformance results and ablation studies. Finally, we conclude\nwith our discussions in Section VIII.\nII. R ELATED WORK\nA. Therapeutic audio-cued and musical interventions in reg-\nulating affective states and enhancing motor rehabilitation\nMusic and audio-cued interventions effectively alleviate de-\npressive symptoms and reduce stress by engaging the parasym-\npathetic branch of the autonomic nervous system [21], [22].These effects are also reflected with changes in physiological\nmeasures, including heart rate variability, blood pressure and\nrespiration [23].\nAffective states are reflected in motor functions [24]. For\nexample gait features such as variations in step/stride lengths\nand gait speed can infer emotional states [24], [25], and\nserve as an observable indicator of mood disorders progression\n[25]\u2013[27]. Motor coordination impairment is proposed to arise\nfrom dysfunctions in dopaminergic circuits, such as the basal\nganglia-thalamo-cortical loops [26]. Affective states also influ-\nence gait initiation through priming action [28]. The cognitive\nfunction that facilitates the postural adjustment period during\nthe initiation of movement lies in the supplementary motor\narea (SMA), premotor cortex and basal ganglia, all of which\nhave connections to the limbic structures that modulate affec-\ntive states [28]. Music-induced emotional contexts decrease\nanticipatory postural adjustments durations [29], suggesting\nthat modulation of affective states could lead to regulating\ngait initiation.\nMusic-based motor rehabilitation exploits the link between\nmotor and emotional regulation, as well as the relationship\nbetween motor and auditory processing networks [30]. The\nentrainment to external musical or auditory cues generates\ntemporal expectations that regulate gait patterns [1]. Continued\nmusical interventions improve motor function by promoting\nneural plasticity by either strengthening affected neuronal\nmotor connections or by triggering compensation mechanisms\n[31]. In particular, it is hypothesised that external sensory cues\ncompensate for impaired time-keeping mechanisms by bypass-\ning the affected basal ganglia circuits through the cerebello-\nthalamo-cortical networks [1], [10], [32].\nModels based on predictive coding [33] and oscillatory brain\nnetwork interactions have been proposed to understand the top-\ndown and bottom-up processes explaining motor-music en-\ntrainment [34], [35]. However these remain largely theoretical\nand challenging to observe in practice. On the other hand,\nBCIs present a way to record the cortical activities related\nto motor function improvements in response to auditory-cued\nstimulus. Publicly available datasets of brain recordings during\ndifferent gait adaptation phases can provide insights into how\nhumans optimise locomotion during rhythmic intervention.\nThese insights can guide future investigations into how and\nwhy music-based interventions are effective, enabling more\npersonalised and targeted rehabilitation strategies. Further-\nmore, music-based BCIs could facilitate home-based moni-\ntoring and earlier, more effective interventions.\nB. Geometric and Statistical Approaches to EEG Signal Pro-\ncessing\nFeature extraction and selection methods capture meaning-\nful information and key characteristics, improving accuracy\nand robustness in EEG-based BCI systems [36]. Common\nspatial patterns (CSP), a well-established binary-class feature\nextraction method, improves separability between classes in\nmotor imagery (MI) based BCIs [18]. CSP spatially filters raw\nsignals by obtaining spatial features that maximise variance in\none class while simultaneously minimising it in the other [18].\n\n--- Page 3 ---\nJOURNAL OF XXXX, VOL. X, NO. X, XX XXXX 3\nAmong several CSP extensions, Filter bank CSP (FBCSP)\nis widely adopted [36]. FBCSP considers frequency band-\nspecific spatial features and selects the most discriminative\nfeatures across all bands [37]. While FBCSP improves perfor-\nmance by exploiting the concept that different EEG frequency\nbands would contain distinct task-related information, this\nmay limit its generalisability across subjects. Despite reported\nsuccess in improving classification performances, CSP relies\non representative covariance matrix estimates ; therefore, it\ncan be highly sensitive to noise. Furthermore, it has also been\nshown to overfit in small datasets [18], [38], [39]. Therefore,\nLotte and Guan [18] encourage the regularisation of either\nthe CSP objective function or the spatial covariance matrix\nestimates.\nAn alternative approach improves classification performance\nby directly exploiting the covariance structures, capturing sta-\ntistical relationships between spatial regions [40]. Covariance\nstructures are by definition Symmetric Positive Definite (SPD)\nmatrices, which form a differentiable manifold [14], [19].\nCorrect handling of these matrices relies on differential geome-\ntry, such as Riemannian geometry. Consequently, classification\nmethods involving metric calculation (distance or mean) can-\nnot be accurately approximated using conventional machine\nlearning algorithms with Euclidean computations [14], [19].\nRiemannian classifier such as Riemannian Minimum Distance\nto Mean (RMDM) implement feature classification directly on\nthe Riemannian manifold while appropriately leveraging SPD\ncovariance matrix curvature structures through Riemannian\nmetrics [14], [40]. Alternatively, conventional machine learn-\ning algorithms that rely on Euclidean metrics can be applied\nby projecting each covariance matrix from the manifold to\na tangent space, enabling local Euclidean approximation [19].\nUnlike interpretable CSP spatial features, Riemannian features\npose a challenge to interpret physiologically [40]. Fusing CSP\nand Riemannian features can support interpretability while\npreserving the intrinsic geometric structures of covariance\nmatrices.\nC. Transfer learning in BCI\nHigh variability between individuals\u2019 EEG data creates\nsubstantial challenges for cross-subject and cross-dataset gen-\neralisation in BCI algorithms. Pre-trained models often exhibit\nsignificant performance degradation when applied to new\nsubjects or even different sessions of the same subject [6].\nTransfer learning (TL) leverages data from other subjects or\nsessions to improve learning for a new subject or sessions,\nthereby reducing or eliminating the calibration session require-\nments [41], [42]. Long calibration sessions increase mental\nfatigue in users, reducing experimental effectiveness [43].\nTL theoretical basis stems from the transfer generalisation\ntheory, where knowledge or skills transfer between domains\nrelies on generalising past experiences [42]. Domains must be\nsufficiently connected as if the domains do not share enough\nsimilarities or, conversely, if they are too similar, TL might\nfail [42]. High-domain similarity can occasionally become\nmisleading, resulting in incorrect assumptions and interference\nthat can hinder effective transfer learning [42].Zanini et al. [44] proposes a transfer learning approach\nthrough a \u2018pre-alignment step\u2019, where each training covariance\nmatrix is transformed by recentering the Riemannian centre to\nidentity matrices, reducing covariate shifts. In other words, as\na result of the recentering, the mean of the newly aligned co-\nvariance matrices will be equal to the identity matrix, therefore\nreducing individual differences between the subjects [6], [13],\n[44]. Alternatively, Xu et al. [6] and He and Wu [13] consider\ndirect time-series transformation. He and Wu [13] align each\nindividual subject prior to the aggregated training subjects\u2019\nsignals for classification. Their exploration of reference matrix\nchoice showed positive effects using the Riemannian compared\nto Euclidean mean of the underlying experimental condition\n[13].\nXuet al. [6] propose an \u2018online pre-alignment strategy\u2019\n(OPS) to align testing datasets prior to model\u2019s testing,\neliminating the need for calibration and constant Riemannian\nmean re-calculation when introducing new subjects. Whilst\nthe direct alignment of EEG trials offers greater flexibility\nin classification models and lower computational cost, using\nEuclidean mean addresses only the covariate shift and it\noverlooks prior probability shift (i.e., the distribution of class\nlabels may vary between subjects) and concept shift (i.e., the\nrelationships between EEG features and labels may change\nacross subjects). Consequently, even after alignment, per-class\ndistribution may still have large discrepancies across subjects\nand less separability [13].\nRodrigues et al. [17] proposes overcoming covariate shift\nthrough Procrustes Analysis by matching the statistical dis-\ntribution of covariance matrices using geometric transforma-\ntions (translation, scaling and rotation). Beyond recentering,\nRiemannian Procrustes Analysis (RPA) adds stretching and\nrotation steps to match data spread and align class centres\nbetween source and target datasets [17]. Bleuz \u00b4eet al. [14]\nproposes an RPA-inspired PS operating directly on the tangent\nspace (TS). They introduce a closed-form solution for the\nrotation step using singular value decomposition in tangent\nspace alignment, thus reducing computation time in com-\nparison to its RPA counterpart [14]. Bleuz \u00b4eet al. [14] also\nexplores clustering instead of singular class-wise centres when\nobtaining the anchor points in the rotation step. Unlike He and\nWu [13], both Rodrigues [17] and Bleuz \u00b4eet al. [14] combines\nmultiple training subjects without preserving individual differ-\nences. This approach could lose subject-specific structures as\nit treats individual signals as if they were obtained from a\nsingle subject, potentially causing covariance space distortion\nand misrepresentation through diluted class structures.\nIII. P RELIMINARIES\nWe segment EEG windows from adaptive and non-adaptive\nheel strikes to create corresponding trials, E\u2208Rt\u00d7e\u00d7s,\nwhere tdenotes the number of trials, ethe number of chan-\nnels/electrodes and sthe number of time samples respectively.\nThe spatial covariance matrix for the trial iis calculated using\nCi=1\ns\u22121EiET\niwhere ETdenotes the transpose of the EEG\nmatrix for trial i.\nCommon Spatial Patterns (CSP) provide spatial filters to\ntransform the raw EEG signals, highlighting features that\n\n--- Page 4 ---\nJOURNAL OF XXXX, VOL. X, NO. X, XX XXXX 4\ncontribute more strongly to discriminate between mental\nstates while suppressing less informative components. Spatial\nfeatures, ware obtained through joint diagonalisation and\neigendecomposition of the class-wise covariance matrices,\nwhich yields eigenvalues and their corresponding eigenvectors\nor, spatial features ( w). Mathematically, this is achieved by\nmaximising the objective function, J(w)in Equation 1, where\nEkandCkrepresent the raw EEG signals and class-wise\ncovariance matrix for class k\u2208 {1,2}, respectively.\nJ(w) =wTET\n1E1w\nwTET\n2E2w=wTC1w\nwTC2w. (1)\nAlternatively, we can exploit the statistical relationship\nencoded in the covariance matrices by leveraging their inherent\ngeometric structure. This approach accounts for the inherent\ncurvature structure of the covariance matrices through the\nprojection and transformation onto the tangent space (TS).\nAfter this transformation, conventional machine-learning al-\ngorithms can be effectively employed in the tangent space,\nwhere Euclidean computations more accurately approximate\nthe true geometric relationships [19].\nThe projection of the covariance matrix and the subsequent\nhalf-vectorisation is described by Equation 2.\nPi= logCref(Ci) =C1/2\nreflogm( C\u22121/2\nrefCiC\u22121/2\nref)C1/2\nref,(2)\nwhere Pirepresent the projected matrix obtained through a\nlogarithmic mapping and half-vectorisation of the correspond-\ning covariant matrix, Ci. The matrix logarithmic operator\nlogm (.)is defined as logm (A) =V D\u2032V\u22121, where D\u2032con-\ntains the logarithms of the diagonal entries of the eigenvalues\n[19]. The definition of the matrix logarithm assumes that A\nis symmetric positive definite, which is true for covariance\nmatrices. The reference covariance matrix Crefis typically\nchosen as the geometric mean, also known as Fr \u00b4echet mean\nof all covariance matrices Cidefined by Equation 3.\nCref=G(C1, ..., C I) = arg min\nCIX\ni=1\u03b42\nR(Cref, Ci),(3)\nwhere \u03b42\nRdenotes the use of Riemannian distance as defined\nin Equation 4\n\u03b4R(C1, C2) =\u2225logm( C\u22121\n1C2)\u2225F= [NX\nn=1log2\u03bbn]1/2,(4)\nwhere \u03bbnare the eigenvalues of C\u22121\n1C2, and|\u00b7|Fdenotes the\nFrobenius norm.\nIV. D ATASET\nWe employed a publicly available dataset [45] (available\nat OpenNeurog.org with accession number ds00197144) to\nobtain our EEG signals for classification. The dataset contains\nEEG recordings of 108-channels from 20 healthy participants\nundergoing audio-cued walking tasks, with two subjects (sub-\njects 19 and 20) excluded due to extensive artefact contam-\nination [45]. In addition, biomechanical data in the form of\nFig. 1. Sliding window process used to segment the signals into our dataset.\nThe top horizontal line represents the EEG signal with vertical ticks marking\nthe onset of heel strikes. The segmentation of the 3 adaptive and non-adaptive\nheel strikes are depicted by the blue and red boxes, respectively. A window\naround the first and third heel strike [ Sx\u2212256:Sx+2+256 ] of the adaptive\ncondition is illustrated by the light orange rectangle. Windows of s= 100\nare slid across the segment for our dataset.\nElectromyography (EMG) signals and kinematic recordings\nfrom 3 goniometers hip, knee and ankle) are provided [45].\nParticipants would participate in a series of audio-cued\nwalking tasks on a treadmill where they were asked to syn-\nchronise their heel strikes with rhythmic cues. After a period\nof steady-walking to a comfortable pace, the tempo of the\nauditory cue would suddenly increase or decrease - signifying\nthe start of the \u2018Advance\u2019 or \u2018Delay\u2019 Tempo. Subsequently,\nparticipants would be required to adapt their gait pattern by\nlengthening or shortening their steps to synchronise to the new\ntempo.\nEEG signals are segmented into adaptive and non-adaptive\nheel strikes defined as the first and middle three heel strikes\nof each \u2018Advance\u2019 and \u2018Delay\u2019 tempo trials. A sliding window\napproach was used to create windows of s= 100 (with a 50%\noverlap) across the sectioned window of [Sx\u2212256 : Sx+2+\n256] around the three respective heel strikes, as visualised in\nFigure 1.\nV. M ETHODOLOGY\nA. Pre-Alignment Strategy for Cross-Subject Transfer Learn-\ning\nWe propose a novel pre-alignment strategy to optimise\ncross-subject transfer learning by independently aligning train-\ning and testing datasets. This approach aims to maximise\nthe extraction of relevant features from training subjects that\ncan be effectively transferred to testing subjects. A graphical\nrepresentation of our proposed PS implementation - \u2018Indi-\nvidual Tangent Space Alignment\u2019 (ITSA) to improve cross-\nsubject classification is demonstrated in Figure 2. We align\neach training subject individually to preserve subject-specific\nstructures as in [13]. Inspired by Bleuz \u00b4eet al. [14], we\ninclude a further two alignment steps aimed at mitigating\nclass-wise distribution shifts. To prevent data leakage during\nthe supervised \u2018rotation\u2019 step, we introduce an additional\n\u2018calibration\u2019 cross-validation.\n1) Subject-Specific Signal Recentering: For each subject\nindividually, we recentre the covariance matrices to establish\na common reference point across all subjects, following an\napproach similar to [13]. This recentering ensures that all\n\n--- Page 5 ---\nJOURNAL OF XXXX, VOL. X, NO. X, XX XXXX 5\nFig. 2. Diagram illustrating the proposed PS - ITSA. Training (yellow) and testing (blue) signals are represented as \u2018squares\u2019, with corresponding covariance\nmeans as circles labelled with the metric used for calculation ( LE = Log-Euclidean). Aligned signals are depicted as \u2018squares with curved corners\u2019 and\nextracted features are displayed as \u2018flattened\u2019 rectangles. The PS can be categorised into three steps (1) recentering (pink), (2) Rescale (orange) and (3)\nRotation (green).\nsubjects share a common global mean, M- the identity matrix.\nSubsequent tangent space projection is implemented after the\n\u2018recentred\u2019 covariance matrix, Crec,as defined in Equation 5.\n\u02c6CTS=LogIe(Crec) =I1\n2elog\u0010\nI\u22121\n2eM\u22121\n2CM\u22121\n2I\u22121\n2e\u0011\nI1\n2e\n= log\u0010\nM\u22121\n2CM\u22121\n2\u0011\n(5)\nwhere Mis calculated as the log-Euclidean mean of the sub-\nject\u2019s covariance matrices, Crepresents the original covariance\nmatrix, and Ieis the identity matrix of dimension e\u00d7e(where\neis the number of channels).\n2) Distribution Matching via Feature Rescaling: Inspired\nby Bleuz \u00b4eet al [14], we include two additional alignment\nsteps. First, we rescale both the training and testing datasets\nto match their distribution around their respective centres of\nmass. This rescaling normalises the average norm within the\nrecentred features space to one as demonstrated in Equation\n6.\n\u02dcCSC=\u02c6CTS\n1\nt\u03a3n\u2225\u02c6CTSn\u2225(6)\nwhere trepresents the number of trials and | \u00b7 |denotes the\nFrobenius norm.\n3) Supervised Rotational Alignment with Calibration: The\nsecond alignment step involves a two-stage process to rotate\nthe testing vectors for optimal alignment with the training\nspace. We first divide the rescaled testing features into two\nsubsets: a calibration subset and an evaluation subset.\nUsing the calibration subset, we derive the transformation\nparameters as follows. For a problem with Kclasses, we\ncalculate the mean of the rescaled vectors for each class k\nin both the training set and the calibration subset, which we\nterm anchor points :\n\u00afCtraink=1\nNtrainkX\nyi=k\u02dcCSCtraini\n\u00afCcalibk=1\nNcalibkX\nyi=k\u02dcCSCcalibi(7)where NtrainkandNcalibkare the number of trials for class k\nin the training set and calibration subset, respectively, and yi\nrepresents the class label for trial i.\nWe then concatenate these class-wise anchor points to form\ntraining and calibration anchor matrices \u00afCtrain,\u00afCcalib:\n\u00afCtrain= [\u00afCtrain 1, . . . , \u00afCtrainK],\u00afCcalib= [\u00afCcalib 1, . . . , \u00afCcalibK]\n(8)\nNext, we compute the cross-product matrix:\nCTC=\u00afCtrain\u00afCT\ncalib (9)\nWe decompose CTCusing singular value decomposition:\nCTC=UDVT(10)\nThe matrices UandVare truncated to retain the mini-\nmum number of features, Nv, that explain 99.9% of variance\nobtaining \u02dcUand\u02dcV. This transformation is then applied to\nthe evaluation subset, which was not used in determining the\nrotation parameters:\n\u02c6CROT eval=\u02dcU\u02dcVT\u02dcCSCeval (11)\nThis two-stage approach ensures that the transformation pa-\nrameters and the evaluation are derived from separate portions\nof the data, maintaining methodological rigour.\nAlgorithm 1 in Appendix Section IX-A provides a pseu-\ndocode for the proposed pre-alignment steps implemented on\nthe training and testing datasets for each iteration of the leave-\none-subject-out cross-validation.\nB. Fusion of Regularised Common Spatial Patterns and Rie-\nmannian Geometry for Enhanced Class Separability\nTo further improve classification performances, we develop\na fusion approach combining Regularised Common Spatial\nPatterns (RCSP) with Riemannian geometry techniques, thus\nleveraging both spatial filtering capabilities and the inherent\ngeometric structure of covariant matrices.\n\n--- Page 6 ---\nJOURNAL OF XXXX, VOL. X, NO. X, XX XXXX 6\n1) Regularisation of Covariance Matrices: We regularise\ncovariance matrices using Diagonal Loading to account for\nthe smaller training dataset and avoid noisy contamination\nand overfitting [18]. Regularisation of the covariance matrix\nis performed by shrinking each covariance matrix towards\nthe identity matrix shown in Equation 12, where \u02dcCkis the\nregularised counterpart of the spatial covariance matrix, Ck\nfor class, k.Iis the identity matrix, skis a scalar scaling\nparameter. \u03b3and\u03b2are the two user-defined regularisation\nparameters ( \u03b3, \u03b2\u2208[0,1]), and Gcis the \u201cgeneric\u201d covariance\nmatrix [18].\n\u02dcCk= (1\u2212\u03b3)\u02c6Ck+\u03b3I\nwith \u02dcCk= (1\u2212\u03b2)skCk+\u03b2Gk(12)\nRegularisation using the Diagonal Loading sets parameters\n\u03b2= 0 and\u03b3is automatically obtained for each covariance\nmatrix using the Ledoit and Wolf\u2019s method [46].\n2) Integration Approaches: Fusing of RCSP with Rieman-\nnian geometry is explored in two approaches: \u2018Sequential\nRCSP-Rie\u2019 and \u2018Parallel RCSP-Rie\u2019.\na) Sequential Integration (\u201cSequential (Seq.) RCSP-\nRiemannian Features\u201d) : \u2018Seq. RCSP-Rie\u2019 combines the two\ntechniques sequentially - firstly spatially filtering signals, fol-\nlowed by TS projection and (half) vectorisation to obtain input\nfeatures. Since the proposed PS implementation includes a TS\nprojection and subsequent vectorisation during the recentering\nstep, spatial filtering is applied before the PS implementation,\nas illustrated by the yellow outline (steps 1 -3) in the top row\nof Figure3 . Subsequent projection and vectorisation are then\nperformed as part of the PS (recentering step), as shown by\nthe pink outline (steps 4-5).\nb) Parallel Integration (\u201cParallel (Par.) RCSP-\nRiemannian Feature\u201d) : \u2018Par. RCSP-Rie\u2019 combines these\ntwo techniques in a parallel approach. Both spatially\nfiltered features and tangent space features are obtained\nsimultaneously and horizontally concatenated to obtain input\nfeatures, as shown in the bottom row of Figure 3. Similar to\nin \u2018Seq. RCSP-Rie\u2019, signals are spatially filtered before the\nPS implementation (steps 1-3a), and features are subsequently\nderived as part of the PS (step 4a). Tangent space features\nare obtained as a product of the implementation of the PS\n(steps 2b-3b) as part of the recentering step (pink outlines).\n3) Classification with Support Vector Machines: For the\nfinal classification stage, we employ support vector machines\n(SVMs) to discriminate between the two mental state classes.\nSVMs are particularly well-suited for this application due to\ntheir effectiveness with high-dimensional feature spaces and\ntheir robustness to overfitting when properly regularised. The\nSVM classifier operates on the features generated from either\nthe sequential or parallel integration approaches described in\nthe previous section. This unified framework enables direct\ncomparison between the different feature extraction methods\nwhile maintaining consistency in the classification stage. For\nall experiments, we use a linear kernel SVM with regularisa-\ntion parameter set to the default parameter ( C= 1.0).\nFig. 3. Diagram illustrating the fusion of RCSP with Riemannian geometry\nimplemented in this study to account. Yellow outlines denotes steps taken\nbefore the PS and pink outlines represent implementations that are included\nwithin the recentering step of \u2018ITSA\u2019. The keys are as follows: Orange square\nboxes - EEG signals, Blue square boxes - covariance matrices, Blue circle -\nCSP filter obtained using arithmetic, depicted by the \u2018A\u2019, Pink square boxes\n- spatially filtered EEG signals, Purple square boxes - Projected dataset onto\nthe tangent space, Rectangular boxes - extract features in the form of taking\nlog-variance. To account for the tangent space projection and subsequent\nvectorisation, the steps outlined in yellow would need to take place prior\nto the implementation of the PS.\nVI. C ROSS -MONTAGE SETUP\nTo simulate montage-specific testing datasets, we extracted\nchannel-specific subsets from our original high-density 108-\nelectrodes dataset, mimicking 10-10 and 10-20 montage con-\nfigurations. Corresponding RCSP filter and projected sig-\nnals were derived using these testing subsets, while training\ndatasets and respective RCSP filters and projected signals were\nobtained from the full 108 configurations. To ensure dimension\ncompatibility prior to classification, feature reduction using\nPCA was applied to both training and testing features. Po-\nsitioning the feature reduction step in the final processing\nstages minimised information loss. Without \u2018ITSA\u2019 implemen-\ntation, feature reduction was applied to the fully-processed\nfeatures post RCSP-Riemannian geometry integration (Seq. -\npurple rectangle and Par. - fused pink and purple rectangle\nin Figure 3). However, with \u2018ITSA\u2019, the supervised \u2018rotation\u2019\nstep requires class-wise information from both training and\ntesting features via the cross-product matrix. Therefore, feature\nreduction was applied following the \u2018rescaling\u2019 step (within the\norange outline of Figure 2) to ensure dimensionality alignment.\nVII. R ESULTS\nA. Implementation Details\nTo appropriately manage the curvature structure of covari-\nance matrices, we implement the TS projection and conse-\nquent half-vectorisation using the pyRiemann package [47]\nin python. We further exploit pyRiemann integration with\nscikit-learn API to incorporate both the Riemannian geometry-\nbased preprocessing and to employ the SVM algorithms.\nB. Leave-one-subject-out (LOSO) classification\nWe employed a leave-one-subject-out cross-validation\n(LOSO-CV) framework to evaluate cross-subject generalisa-\ntion performance while preventing data leakage during the\npre-alignment process. For each of the N subjects, one subject\nwas held out completely for testing while the remaining N-1\nsubjects formed the training subjects. Initial subject-specific\nrecentering was applied independently to each subject using\nonly that subject\u2019s own data to calculate the Log-Euclidean\n\n--- Page 7 ---\nJOURNAL OF XXXX, VOL. X, NO. X, XX XXXX 7\nmean. After recentering, training features from the N-1 sub-\njects were concatenated to form the training set. Subsequent\nrescaled and rotated training features were obtained from\nthis concatenated training set. Following the recentering and\nrescaling of the held-out subject\u2019s data, the features were\ndivided into calibration and evaluation subsets, with rotation\nparameters estimated using a nested 2-fold cross-validation\napproach where each subset alternately served as calibration\ndata to derive transformation parameters and evaluation data\nfor performance assessment. Final performance was computed\nas the average across both folds, ensuring all testing data con-\ntributed to evaluation while maintaining separation between\nparameter estimation and performance evaluation.\nThe proposed pre-alignment strategy - \u2018Individual Tangent\nSpace Alignment\u2019 (ITSA) , demonstrated substantial improve-\nments in classification performance across most subjects for\nboth feature extraction methods ( \u2018Seq. RCSP-Rie\u2019 and \u2018Par.\nRCSP-Rie\u2019) and temporal conditions (Advanced and Delay\nTempos).\n1) Performance Improvements by Condition: In the ad-\nvanced tempo condition, the proposed pre-alignment strategy\nenhanced performance for 10 subjects (subjects 1, 4, 6, 7, 10,\n11, 12, 16, 17, and 18) in both the \u2018Seq. RCSP-Rie\u2019 and \u2018Par.\nRCSP-Rie\u2019 methods (achieving an average F1 score 61.15%\nand 61.34% respectively, representing a 56% improvement rate\nacross the cohort.\nIn the delayed tempo condition, the results showed dif-\nferential improvements between methods. The \u2018Seq. RCSP-\nRie\u2019 improved performance for 8 subjects (subjects 3, 6,\n12, 13, 14, 16, 17 and 18), while the \u2018Par. RCSP-Rie\u2019\nmethod demonstrated more robust improvements, benefiting\n11 subjects (subjects 3, 6, 7, 10, 12, 13, 14, 15, 16, 17 and\n18), achieving a 61% rate. The averaged F1 performance for\nthe \u2018Seq.\u2019 and \u2018Par. RCSP-Rie\u2019 approaches were 57.28% and\n58.52%, respectively.\nTables IV and VII in Appendix Section IX-B presents the\nindividual F1 scores (%) for each testing subject.\n2) Statistical Analysis and Significance Testing: Tables I\npresent the LOSO-CV F1 scores (%) averaged across all\nsubjects for the \u2018Advance\u2019 and \u2018Delay\u2019 conditions, respec-\ntively, comparing our proposed method \u2018ITSA\u2019 PS against the\nbaseline (where no pre-alignment strategy is implemented).\nStatistical analysis confirmed significant improvements\nacross all tested configurations:\n\u2018Seq. RCSP-Rie\u2019: The Advance Tempo condition showed\nsignificant improvement ( t(17) = 2 .3256, p= 0.03267 ), while\nthe Delay condition demonstrated even stronger significance\n(W= 156 .00, p= 0.0021 ).\n\u2018Par. RCSP-Rie\u2019: Both conditions yielded significant im-\nprovements, with the Advance condition achieving (Advance:\nt(17) = 2 .6830, p= 0.01572 ) and Delay condition ( t(17) =\n43.0551, p= 0.0008 ).\nAll statistically significant improvements( p <0.05), using\ntwo-sided statistical tests, are indicated by \u2018(**)\u2019 in Tables I.\nTo determine statistical significance, we first performed\nnormality testing using the Lilliefors test on the performance\nscores difference \u2018ITSA\u2019 vs. Baseline . The analysis\nshowed that three of the four condition-method combinationsfollowed normal distributions: \u2018Seq. RCSP-Rie\u2019 in the \u2018Ad-\nvance\u2019 conditions and \u2018Par. RCSP-Rie\u2019 in both the \u2018Advance\u2019\nand \u2018Delay\u2019 Tempo conditions. For these normally distributed\ndifferences, paired t-tests were employed. However, the \u2018Seq.\nRCSP-Rie\u2019 method in the Delay condition deviated signifi-\ncantly from normality (p = 0.0452), necessitating the use of\nthe non-parametric Wilcoxon signed-rank test.\nC. Ablation Study of pre-alignment components\nTo systematically evaluate the contribution of individual\ncomponents within our proposed pre-alignment strategy, we\nconducted an ablation study comparing our \u2018Individual Tan-\ngent Space Alignment\u2019 (ITSA) method against two state-of-\nthe-art pre-alignment baselines described in Section II-C that\nwe refer to as: a) \u2018Adaptive M\u2019 [13] and b) \u2018TS\u2019 [14]. The\n\u2018Adaptive M\u2019 method proposed by He and Wu (2020) [13]\naligns each subject\u2019s covariance matrices computed from the\nadapted signals through individual recentering as implemented\nin our proposed \u2018ITSA\u2019 - however, unlike\u2018ITSA\u2019, the alignment\nof signals is only performed through recentering and does not\nrescale or rotate features. To improve computational efficiency\nand enable the use of non-Riemannian machine learning\nalgorithms, transformation and alignment of the covariance\nmatrices occur in Euclidean space [13] using the arithmetic\ncentre as a reference. Furthermore, it was reported higher\nperformance with the use of the Euclidean mean of the\nimagery trials of the motor-imagery signals. We adapted this\nstrategy to align the training trials by taking Euclidean mean\nof trials from \u2018adaptive\u2019 heel strikes - thus, the term \u2018Adaptive\nM\u2019 is used.\nWe also explored the effect that alignment in the tangent\nspace has on the classification performance. The \u2018TS\u2019 method,\nproposed by Bleuz \u00b4eet al [14] initially recentres the training\ncovariance matrices choosing the log-Euclidean mean as the\nreference before projecting to the tangent space and subse-\nquent half vectorisation. Two additional alignment steps, sim-\nilar to \u2018ITSA\u2019 - \u2018rescaling\u2019 and \u2018rotation\u2019 are implemented to\nensure alignment of class means and consistency of dispersion\naround the mean. Table II provides a detailed breakdown\nof the components included in each method, facilitating a\ncomprehensive comparison of their architectural differences.\n1) Component-wise Performance Analysis: Advance\nTempo Condition: The analysis revealed that pre-alignment\nstrategies failed to improve performance for only a limited\nnumber of subjects. Specifically, five subjects (subjects 3,\n9, 13, 14 and 15) in the \u2018Seq. RCSP-Rie\u2019 method and two\n(subjects 3 and 13) in the \u2018Par. RCSP-Rie\u2019 method did\nnot show improvement with the use of any PS technique,\nrepresenting failure rates of 28% and 11%, respectively.\nTangent space alignment methods (both \u2018TS\u2019 and \u2018ITSA\u2019)\nachieved the highest performance, with optimal results for 10\nout of 18 subjects (56%) in both feature extraction methods\n(Averaged F1 scores: 57.44 (\u2018Adaptive M\u2019) vs. 60.99 (\u2018TS\u2019)\nvs. 61.15 (\u2018ITSA\u2019) for \u2018Seq. RCSP-Rie\u2019, and 59.29 (\u2018Adaptive\nM\u2019) vs. 61.00 (\u2018TS\u2019) vs. 61.34 (\u2018ITSA\u2019) for \u2018Par. RCSP-Rie\u2019).\nDelay Tempo Condition: The \u2018Delay Tempo\u2019 condi-\ntion demonstrated more consistent improvements across pre-\nalignment strategies. Only subject 2 in the \u2018Seq. RCSP-Rie\u2019\n\n--- Page 8 ---\nJOURNAL OF XXXX, VOL. X, NO. X, XX XXXX 8\nTABLE I\nF1- SCORES FOR CLASSIFICATION OF ADVANCE AND DELAY TEMPO FEATURES COMPARING THE BASELINE (WITHOUT PS) AND OUR PROPOSED PS\n(\u2018ITSA\u2019). M ETRICS ARE REPORTED FOR THE TWO METHODS OF FUSING RCSP WITH RIEMANNIAN GEOMETRY : SEQ. RCSP-R IE AND PAR. RCSP-R IE.\nAVERAGED PERFORMANCES AND STANDARD DEVIATIONS ACROSS TESTING SUBJECTS ARE REPORTED . 95% CONFIDENCE INTERVALS ARE ALSO\nPROVIDED . STATISTICALLY SIGNIFICANT IMPROVEMENTS RESULTING FROM THE PS (p < 0.05)ARE DENOTED BY (**).\nAdvance Tempo Delay Tempo\nBaseline (No PS) LOSO (\u2018ITSA\u2019 - proposed PS) Baseline (No PS) LOSO (\u2018ITSA\u2019 - proposed PS)\nSeq. RCSP-Rie (%) 54.39 \u00b111.05 (CI: 48.90 -\n59.88)61.15 \u00b17.27 (CI: 57.54 -\n64.77) (**)41.96 \u00b118.10 (CI: 32.96 -\n50.97)57.28 \u00b15.65 (CI: 54.47 -\n60.09) (**)\nPar. RCSP-Rie (%) 56.23 \u00b18.43 (CI: 52.03 -\n60.42)61.34 \u00b15.49 (CI: 58.60 -\n64.07) (**)42.65 \u00b119.52 (CI: 32.94 -\n52.36)58.52 \u00b15.65 (CI: 55.71 -\n61.33) (**)\nTABLE II\nABLATION TABLE ON PRE -ALIGNMENT STRATEGIES . CHECKMARKS\nINDICATE THE PRESENCE OF THE COMPONENT IN PRE -ALIGNMENT\nSTRATEGY .\nrecentering\n(per subject)Rescaling\nStepRotation\nStep\nBaseline (w/out PS)\n\u2018Adaptive M\u2019 [13] \u2713\n\u2018TS\u2019 [14] \u2713 \u2713\n\u2018ITSA\u2019 - proposed method \u2713 \u2713 \u2713\nmethod failed to benefit from any pre-alignment approach,\nwhile all subjects in the \u2018Par. RCSP-Rie\u2019 method showed\nperformance gains with at least one strategy.\nConsistent with the \u2018Advance Tempo\u2019 condition, tangent\nspace methods achieved superior performance for the majority\nof subjects (8 out of 18 subjects (44%) in \u2019Seq. RCSP-Rie\u2019 and\n11 out of 18 subjects (61%) in \u2019Par. RCSP-Rie\u2019). Averaged\nF1 scores are reported as follows: 56.38 (\u2018Adaptive M\u2019) vs.\n57.13 (\u2018TS\u2019) vs. 57.28 (\u2018ITSA\u2019) for \u2018Seq. RCSP-Rie\u2019, and\n55.08 (\u2018Adaptive M\u2019) vs. 58.45 (\u2018TS\u2019) vs. 58.52 (\u2018ITSA\u2019) for\n\u2018Par. RCSP-Rie\u2019.\nTable III presents the F1 scores across all subjects for the\n\u2018Advance\u2019 and \u2018Delay\u2019 conditions, respectively. All three pre-\nalignment strategies (\u2018Adaptive M\u2019, \u2018TS\u2019, and \u2018ITSA\u2019) in the\nDelay tempo and the two tangent-space PS (\u2018TS\u2019 and \u2018ITSA\u2019)\nin the Advance tempo demonstrated statistically significant\nimprovements over baselines (LOSO-CV without the use of\nPS) across both temporal conditions and feature extraction\nmethods.\nBoth \u2018TS\u2019 and \u2018ITSA\u2019 methods consistently achieved the\nhighest classification performance, with statistical significant\nimprovements compared to baselines across all conditions.\nThe superior performance of tangent space methods com-\npared to \u2018Adaptive M\u2019 suggests that the primary benefit results\nfrom the additional rescaling and rotation steps in the tangent\nspace rather than solely from individual recentering. Our\nproposed method, \u2018ITSA\u2019, consistently outperformed \u2018TS\u2019,\ndemonstrating the added value of an initial subject-specific\nrecentering around the mean before the tangent space projec-\ntion, to allow generalisation in a LOSO setup.\nD. Cross-Montage Setup\nWe simulated an experiment to determine if models trained\non high-density EEG data (108-channels) could be applied\nto a lower-density configuration. The experiment is aimedto determine if pre-trained model can be used effectively in\na portable EEG set up that would be more suitable for a\nreal-world deployment, offering reduced complexity in set-\nup and computational demand. We chose channel subsets\nthat corresponded to 10-20 and 10-10 montages (19 and 61\nelectrodes, excluding reference channels. To determine the\noptimal number of features to reduce without significant loss\nof performance - we conducted a feature reduction experiment\nas described in Appendix Section IX-E. We deduced that a\nreduction of training features to retain 25% and 1% (for 10-10\nand 10-20 montage) respectively would not cause significant\nloss in classification performances (Averaged performance loss\n- Seq: 3.47 (25%) and 4.72 (1%), Par: 3.14 (25%) and 4.80\n(1%)). Feature reduction was implemented towards the end\nof the pipelines. Without the use of \u2018ITSA\u2019, feature reduction\nwas implemented on vectorised elements of spatially filtered\ncovariant matrices that have been projected to the tangent\nspace (i.e., processed features post RCSP-Riemannian geome-\ntry integration). This reduced the original dimensionality from\n5886 and 5994 (for \u2018Seq.\u2019 and \u2018Par. RCSP-Rie\u2019 approach,\nrespectively) to 1472 and 1498 features by retaining 25% or 59\nand 60 by retaining 1%. As the rotation step in \u2018ITSA\u2019 relies on\nclass-wise information from both training and testing features\nvia the cross-product matrix, feature reduction was recentred\nand rescaled half-vectorised tangent features (i.e., during the\nPS integration). This reduced the original dimensionality from\n5886 and 11772 (for \u2018Seq.\u2019 and \u2018Par. RCSP-Rie\u2019 approach,\nrespectively) to 1472 and 2944 features by retaining 25% or\n59 and 118 by retaining 1%.\nFigure 4 depicts the LOSO-CV classification results for\nour cross-montage experiment. We simulate the training of\nour SVM model using high-density dataset of 108-electrodes,\nwhile testing on a lower-density 10-10 or 10-20 montage,\nconsisting of 60 or 19-electrodes respectively. We employed\nPCA for feature reduction to ensure both training and testing\ndimensionality were consistent prior to input into the classifier.\nTraining features were reduced to retain 25% and 1% of\noriginal features when simulating testing datasets from 10-10\nand 10-20 montages.\nOur results demonstrate the potential of cross-montage\nexperimentation, yielding promising outcomes. For both Seq.\nand Par. RCSP-Rie approaches and temporal conditions, ap-\nplying \u2018ITSA\u2019 across all three montages (108 electrodes, 10-10\nand 10-20) consistently outperformed their respective baseline\ncounterparts when \u2018ITSA\u2019 was not implemented. Overall, some\n\n--- Page 9 ---\nJOURNAL OF XXXX, VOL. X, NO. X, XX XXXX 9\nTABLE III\nF1- SCORES FOR CLASSIFICATION OF ADVANCE TEMPO FEATURES FROM OUR LOSO-CV ABLATION STUDY . W E COMPARED OUR PROPOSED PS\n(\u2018ITSA\u2019) WITH TWO PSBASELINES - \u2018A DAPTIVE M\u2019 [13] AND \u2018TS\u2019 [14]. M ETRICS ARE REPORTED FOR THE TWO METHODS OF FUSING RCSP WITH\nRIEMANNIAN GEOMETRY : SEQ. RCSP-R IE AND PAR. RCSP-R IE. AVERAGED PERFORMANCES AND STANDARD DEVIATIONS ACROSS TESTING SUBJECT\nAND LOSO. 95% CONFIDENCE INTERVALS ARE ALSO PROVIDED . STATISTICALLY SIGNIFICANT IMPROVEMENT RESULTING FROM THE IMPLEMENTATION\nOFPSMETHODS (p < 0.05)ARE DENOTED BY (**).\nAdvance Tempo\nLOSO (\u2018Adaptive M\u2019) [13] LOSO (\u2018TS\u2019) [14] LOSO (\u2018ITSA\u2019 - proposed PS)\nSeq. RCSP-Rie (%) 57.44 \u00b15.35 (CI: 54.78 - 60.10) 60.99 \u00b16.41 (CI: 57.80 - 64.18) (**) 61.15 \u00b17.27 (CI: 57.54 - 64.77) (**)\nPar. RCSP-Rie (%) 59.29 \u00b14.13 (CI: 57.24 - 61.35) 61.00 \u00b15.63 (CI: 58.21 - 63.80) (**) 61.34 \u00b15.49 (CI: 58.60 - 64.07) (**)\nDelay Tempo\nLOSO (\u2018Adaptive M\u2019) [13] LOSO (\u2018TS\u2019) [14] LOSO (\u2018ITSA\u2019 - proposed PS)\nSeq. RCSP-Rie (%) 56.38 \u00b16.41 (CI: 63.19 - 59.5) (**) 57.13 \u00b15.50 (CI: 54.40 - 59.87) (**) 57.28 \u00b15.65 (CI: 54.47 - 60.09) (**)\nPar. RCSP-Rie (%) 55.08 \u00b19.25 (CI: 50.48 - 59.66) (**) 58.45 \u00b15.65 (CI:55.64 - 61.26) (**) 58.52 \u00b15.65 (CI :55.71 - 61.33) (**)\nloss of performance can be observed when reducing the testing\ndataset to lower montages in the Advance Tempo. Without the\nuse of \u2018ITSA\u2019, the average performance reduction was 4.54%\nand 7.07% for the 10-10 montage and 5.93% and 7.80% for the\n10-20 montage, when using Seq. and Par. RCSP-Rie feature\nrespectively. In contrast, implementing \u2018ITSA\u2019 resulted in\nmore consistent performance across both montages. Notably,\naverage classification performances decreased by only 1.60%\nand 1.86% for the 10-10 montage (60 electrodes), and 1.69%\nand 1.62% 10-20 montage (19 electrodes) when using Seq.\nand Par. RCSP-Rie feature respectively.\nOn the contrary, in the Delay condition, performance in-\ncreased with the smaller testing montages, 10-20 montage (60\nelectrodes) and 10-10 montage (19 electrodes). Without the\nuse of \u2018ITSA\u2019, the average performance in the \u2018Seq. RCSP-Rie\u2019\napproach increased by 6.17% and 5.8% for the 10-10 montage\nand 10-20 montage, respectively. A similar observation is\nmade in the \u2018Par. RCSP-Rie\u2019 approach with an increase\nof 5.80% and 7.07% for 10-10 and 10-20 configurations.\nSimilar to the Advance Tempo, \u2018ITSA\u2019 implementation led\nto steadier performance across montages in comparison to\nbaseline counterparts, with smaller increases of 3.55% and\n2.15% for 10-10 montage and 4.85% and 2.67% increase in\nperformance for 10-20 montage with respective Seq. and Par.\nRCSP-Rie features.\nNotably, \u2018ITSA\u2019 maintained enhanced classification perfor-\nmance using only 19 or 60 electrodes, surpassing baseline\nperformance achieved with a high-density test configuration\nfor both Seq. and Par. RCSP-Rie approaches and temporal\nconditions.\nOur findings demonstrate the promising capability of lever-\naging high-density pre-trained models for effect classification\nof EEG signals from reduced-density montages such as the\n10-10 and 10-20. Our results further support that the use of\n\u2018ITSA\u2019 improves models\u2019 generalisability to unseen subjects\neven in lower-density configurations. Thereby, we believe the\nimplementation of \u2018ITSA\u2019 on a cross-montage experiment\nhas the potential to reduce computational demand, set-up\ncomplexity, and in general improve practicality for real-world\ndeployment.\nE. Performance Curves\nTo evaluate the scalability and robustness of our proposed\npre-alignment strategy under varying data availability con-\n(a)\n(b)\nFig. 4. LOSO classification performances (F1 scores %) for cross-montage\nexperiment for (a) Advance and (b) Delay tempo. Simulation of testing\ndatasets using 60 and 19 electrodes (simulating dataset from a 10-10 and\n10-20 montage) were tested on model trained with our high-density training\nof 108 electrodes. Lower-density subsets representing 10-10 and 10-20 dataset\nwere extracted from original testing datasets of 108 electrodes. Comparisons\nbetween baseline performance (blue) and performance after implementation\nof proposed \u2018ITSA\u2019 (green) are depicted.\nditions, we analysed the relationship between training set\nsize and classification performance. This analysis provides\ncritical insights into the method\u2019s effectiveness in data-limited\nscenarios, which are common in clinical EEG applications.\nFigure 5 presents performance curves for both Advance and\nDelay tempo conditions, using subjects 1 (red), 3 (blue), and\n18 (orange) as representative testing subjects in our LOSO-CV\nframework. The training size is represented by the number of\ntraining subjects ( Ntrain), with the maximum available training\nsize being Ntrain= 17 (utilising all remaining subjects after\nexcluding the test subject).\nFor training sizes smaller than the maximum ( Ntrain<17),\nwe implemented a robust 10-fold cross-validation procedure.\nIn each fold, Ntrainsubjects were randomly sampled from\nthe pool of 17 available training subjects. Our proposed pre-\nalignment strategy was applied consistently across all folds, as\ndetailed in Section V-A. Performance metrics for each Ntrain\n\n--- Page 10 ---\nJOURNAL OF XXXX, VOL. X, NO. X, XX XXXX 10\nvalue were obtained by averaging across the 10 folds to ensure\nstatistical reliability. The baseline performance (grey dashed\nline) represents the averaged F1 scores across all LOSO-CV\ntesting subjects without pre-alignment strategy implementa-\ntion.\nThe performance curves display both observed and pre-\ndicted performance metrics. Observed F1 scores are marked\nwith crosses at discrete training sizes ( Ntrain= 5,9,15,17),\nwhile predicted metrics are represented by solid circles based\non two projection models. The linear projection (dotted line)\nassumes a consistent linear relationship between training size\nand performance. The logarithmic projection (dash-dotted line)\nmodels the expected diminishing returns with increasing train-\ning size.\nAs anticipated, classification performance decreased con-\nsistently across all testing subjects as training size decreased.\nThis trend was maintained for both temporal conditions, con-\nfirming the expected relationship between available training\ndata and model performance.\nDespite substantial reductions in training data ( >50%\nreduction, e.g., Ntrain= 5), the proposed method demonstrated\nremarkable resilience. Performance degradation remained min-\nimal, with F1 score decreases of 5% between all tested sub-\njects examined. Furthermore, even at minimum training sizes,\nperformance consistently exceeded baseline comparisons.\nVIII. D ISCUSSION AND CONCLUSIONS\nIn this study, we proposed a novel pre-alignment strategy -\n\u2018ITSA\u2019 , integrated with a fusion of Common Spatial Patterns\nand Riemannian geometry to improve the model\u2019s general-\nisability in a leave-one-subject-out cross-validation (LOSO-\nCV). Our approach combines subject-independent recentering\nto align all subjects to a common representational subspace\nwith subsequent tangent space alignment steps that preserve\nthe covariance matrix geometric structure.\nThe substantial performance degradation observed without\npre-alignment highlights the negative impact of inter-subject\nvariability on model generalisation. Our proposed method\ndemonstrated consistent statistical improvements across all\nfeature extraction methods and temporal conditions. To our\nknowledge, we are the first to demonstrate in a LOSO test-\ning setup that through alignment and normalisation of EEG\nfeatures across participants, inter-subject variability can be\nmitigated significantly.\nThe ablation study demonstrated that subject-independent\nrecentering and consequent rescaling and rotation steps in the\ntangent space, resulted in a more effective mitigation of inter-\nsubject variability in comparison to current PS proposed in\nliterature. We also observed some subject-specific variations\nin the effectiveness of the PS; however, we note that its appli-\ncation rarely resulted in significant performance deterioration\nin the \u2018unsuccessful subjects. This suggests that our proposed\nPS is relatively robust and holds promise for generalisation\nacross a diverse subject population.\nCrucially, our cross-montage experiments demonstrated the\npractical advantage of the ITSA-RCSP-Riemannian fusion\nframework. When training on high-density 108-electrode con-\n(a)\n(b)\nFig. 5. Performance curves depicting the relationship between the training\nsize (number of subjects Ntrain) and LOSO-CV performance (F1 scores, %)\nfor subjects 1 (red), 3 (blue) and 18 (orange) as testing subjects for the\n(a) Advance and (b) Delay tempo. Observed F1 scores are reported for\nNtrain = 5,9,15,17(marked as a cross). Predicted F1 scores (solid dots)\nfor a logarithmic (dashdotted linestyle) and linear (dotted linestyle) fit are\ndisplayed. Baselines, without \u2018ITSA\u2019 (grey, dashed lines) are obtained as the\naveraged F1 score across all testing subjects where Ntrain= 17 .\nfigurations and testing on reduced montages (10-10 and 10-\n20), the combined approach maintained superior classifica-\ntion performance compared to baseline methods. This cross-\nmontage generalisability addresses a critical limitation in BCI\ndeployment, where training and testing setups may differ\nsignificantly in real-world applications.\nImproving BCI systems generalisability, as demonstrated in\nour LOSO-CV and cross-montage deployment strategies with\nITSA-RCSP-Riemannian integration, represents a critical step\ntowards real-world BCI integration into music-based interven-\ntions. The ability to train on high-density electrode arrays\nwhile maintaining performance on clinical-grade montages\nsignificantly enhances practical deployment feasibility. This\napproach can also facilitate deeper investigations into the neu-\nral mechanisms that support auditory-cued motor responses.\nOne method to studying cognitive processes underlying rhyth-\nmic entrainment involves disrupting steady-state behaviour and\nobserving system\u2019s responses during return to stability [48].\nGeneralisable BCIs can therefore support personalised musical\ninterventions, where the musical stimuli are dynamically tai-\nlored to provide external timekeeping cues while modulating\naffective state, stabilising gait patterns and enhancing user\u2019s\nability to initiate and adapt gait parameters.\n\n--- Page 11 ---\nJOURNAL OF XXXX, VOL. X, NO. X, XX XXXX 11\nREFERENCES\n[1] C.-E. Benoit, S. Dalla Bella, N. Farrugia, H. Obrig, S. Mainka,\nand S. A. Kotz, \u201cMusically cued gait-training improves\nboth perceptual and motor timing in parkinson\u2019s disease,\u201d\nFrontiers in Human Neuroscience , vol. 8, Jul. 2014. [On-\nline]. Available: https://www.frontiersin.orghttps://www.frontiersin.org/\njournals/human-neuroscience/articles/10.3389/fnhum.2014.00494/full\n[2] L. Moumdijian, J. Buhmann, I. Willems, P. Feys, and M. Leman,\n\u201cEntrainment and syncronization to auditory stimuli during walking\nin healthy and neurological populations: A methodological systematic\nreview,\u201d Front Hum Neurosci , vol. 12, no. 263, pp. 1\u201316, 2018.\n[3] K. Devlin, J. T. Alshaikh, and A. Pantelyat, \u201cMusic therapy and\nmusic-based interventions for movement disorders,\u201d Current Neurology\nand Neuroscience Reports , vol. 19, no. 11, p. 83, Nov. 2019. [Online].\nAvailable: https://doi.org/10.1007/s11910-019-1005-0\n[4] N. Lai-Tan, M. G. Philiastides, F. Kawsar, and F. Deligianni,\n\u201cToward personalized music-therapy: A neurocomputational modeling\nperspective,\u201d IEEE Pervasive Computing , vol. 22, no. 3, p. 27\u201337,\nJul. 2023. [Online]. Available: https://ieeexplore.ieee.org/document/\n10170750\n[5] R. Mane, T. Chouhan, and C. Guan, \u201cBci for stroke rehabilitation:\nmotor and beyond,\u201d Journal of Neural Engineering , vol. 17, no. 4,\np. 041001, Aug. 2020. [Online]. Available: https://dx.doi.org/10.1088/\n1741-2552/aba162\n[6] L. Xu, M. Xu, Y . Ke, X. An, S. Liu, and D. Ming, \u201cCross-\ndataset variability problem in eeg decoding with deep learning,\u201d\nFrontiers in Human Neuroscience , vol. 14, 2020. [Online]. Avail-\nable: https://www.frontiersin.org/journals/human-neuroscience/articles/\n10.3389/fnhum.2020.00103\n[7] M. Orban, M. Elsamanty, K. Guo, S. Zhang, and H. Yang, \u201cA review of\nbrain activity and eeg-based brain\u2013computer interfaces for rehabilitation\napplication,\u201d Bioengineering , vol. 9, no. 12, p. 768, Dec. 2022. [Online].\nAvailable: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9774292/\n[8] T. A. Deuel, J. Wenlock, A. McGovern, J. Rosenthal, and\nJ. Pampin, \u201cMusical auditory feedback bci: clinical pilot study of\nthe encephalophone,\u201d Frontiers in Human Neuroscience , vol. 19,\nJun. 2025. [Online]. Available: https://www.frontiersin.org/journals/\nhuman-neuroscience/articles/10.3389/fnhum.2025.1592640/full\n[9] W.-C. Chang, L.-W. Ko, K.-H. Yu, Y .-C. Ho, C.-H. Chen, Y .-J. Jong,\nand Y .-P. Huang, \u201cEeg analysis of mixed-reality music rehabilitation\nsystem for post-stroke lower limb therapy,\u201d Journal of the Society\nfor Information Display , vol. 27, no. 6, p. 372\u2013380, 2019. [Online].\nAvailable: https://onlinelibrary.wiley.com/doi/abs/10.1002/jsid.787\n[10] J. G \u00b4omez-Gonz \u00b4alez, P. Mart \u00b4\u0131n-Casas, and R. Cano-de-la Cuerda,\n\u201cEffects of auditory cues on gait initiation and turning in patients\nwith parkinson\u2019s disease,\u201d Neurolog \u00b4\u0131a (English Edition) , vol. 34, no. 6,\np. 396\u2013407, Jul. 2019. [Online]. Available: https://www.sciencedirect.\ncom/science/article/pii/S2173580818301603\n[11] S. Ghai, I. Ghai, G. Schmitz, and A. O. Effenberg, \u201cEffect of rhythmic\nauditory cueing on parkinsonian gait: A systematic review and meta-\nanalysis,\u201d Scientific reports , vol. 8, no. 1, pp. 1\u201319, 2018.\n[12] S. Saha and M. Baumert, \u201cIntra- and inter-subject variability in\neeg-based sensorimotor brain computer interface: A review,\u201d Frontiers\nin Computational Neuroscience , vol. 13, 2020. [Online]. Avail-\nable: https://www.frontiersin.org/journals/computationalneuroscience/\narticles/10.3389/fncom.2019.00087\n[13] H. He and D. Wu, \u201cTransfer learning for brain-computer interfaces: A\neuclidean space data alignment approach,\u201d IEEE transactions on bio-\nmedical engineering , vol. 67, no. 2, p. 399\u2013410, Feb. 2020.\n[14] A. Bleuz \u00b4e, J. Mattout, and M. Congedo, \u201cTangent space\nalignment: Transfer learning for brain-computer interface,\u201d Frontiers\nin Human Neuroscience , vol. 16, Dec. 2022. [Online]. Avail-\nable: https://www.frontiersin.org/journals/human-neuroscience/articles/\n10.3389/fnhum.2022.1049985/full\n[15] X. Gu, F. Deligianni, J. Han, X. Liu, W. Chen, G.-Z. Yang, and\nB. Lo, \u201cBeyond supervised learning for pervasive healthcare,\u201d IEEE\nReviews in Biomedical Engineering , vol. 17, p. 42\u201362, 2024. [Online].\nAvailable: https://ieeexplore.ieee.org/document/10189101/\n[16] L. Mayaud, S. Cabanilles, A. Van Langhenhove, M. Congedo,\nA. Barachant, S. Pouplin, S. Filipe, L. P \u00b4et\u00b4egnief, O. Rochecouste,\nE. Azabou, C. Hugeron, M. Lejaille, D. Orlikowski, and D. Annane,\n\u201cBrain-computer interface for the communication of acute patients:\na feasibility study and a randomized controlled trial comparing\nperformance with healthy participants and a traditional assistive device,\u201d\nBrain-Computer Interfaces , vol. 3, no. 4, p. 197\u2013215, Oct. 2016.\n[Online]. Available: https://doi.org/10.1080/2326263X.2016.1254403[17] P. L. C. Rodrigues, C. Jutten, and M. Congedo, \u201cRiemannian\nprocrustes analysis: Transfer learning for brain\u2013computer interfaces,\u201d\nIEEE Transactions on Biomedical Engineering , vol. 66, no. 8, p.\n2390\u20132401, Aug. 2019. [Online]. Available: https://ieeexplore.ieee.org/\ndocument/8588384/?arnumber=8588384\n[18] F. Lotte and C. Guan, \u201cRegularizing common spatial patterns to improve\nbci designs: Unified theory and new algorithms,\u201d IEEE Transactions\non Biomedical Engineering , vol. 58, no. 2, p. 355\u2013362, Feb. 2011.\n[Online]. Available: http://ieeexplore.ieee.org/document/5593210/\n[19] A. Barachant, S. Bonnet, M. Congedo, and C. Jutten, \u201cClassification\nof covariance matrices using a riemannian-based kernel for\nbci applications,\u201d Neurocomputing , vol. 112, p. 172\u2013178, Jul.\n2013. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/\nS0925231213001574\n[20] N. Lai-Tan, M. G. Philiastides, and F. Deligianni, \u201cFusion of spatial\nand riemannian features to enhance detection of gait adaptation mental\nstates during rhythmic auditory stimulation,\u201d in 2024 12th International\nConference on Affective Computing and Intelligent Interaction (ACII) ,\n2024, pp. 283\u2013290.\n[21] M. Leggieri, M. H. Thaut, L. Fornazzari, T. A. Schweizer, J. Barfett,\nD. G. Munoz, and C. E. Fischer, \u201cMusic intervention approaches\nfor alzheimer\u2019s disease: A review of the literature,\u201d Frontiers in\nNeuroscience , vol. 13, no. 132, pp. 1\u20138, 2019. [Online]. Available:\nhttps://doi.org/10.3389/fnins.2019.00132\n[22] J. L. Axelsen, J. S. J. Meline, W. Staiano, and U. Kirk, \u201cMindfulness\nand music interventions in the workplace: assessment of sustained\nattention and working memory using a crowdsourcing approach,\u201d BMC\nPyschology , vol. 10, no. 108, pp. 1\u201316, 2022.\n[23] J. Kulinski, E. K. Ofori, A. Visotcky, A. Smith, R. Sparapani, and\nJ. L. Fleg, \u201cEffects of music on the cardiovascular system,\u201d Trends in\ncardiovascular medication , vol. 32, no. 6, pp. 390\u2013398, 2022.\n[24] F. Deligianni, Y . Guo, and G.-Z. Yang, \u201cFrom emotions to mood\ndisorders: A survey on gait analysis methodology,\u201d IEEE journal of\nbiomedical and health informatics , vol. 23, no. 6, p. 2302\u20132316, Nov.\n2019.\n[25] D. Adolph, W. Tschacher, H. Niemeyer, and J. Michalak, \u201cGait\npatterns and mood in everyday life: A comparison between depressed\npatients and non-depressed controls,\u201d Cognitive Therapy and Research ,\nvol. 45, no. 6, p. 1128\u20131140, Dec. 2021. [Online]. Available:\nhttps://doi.org/10.1007/s10608-021-10215-7\n[26] R. Feldman, S. Schreiber, C. Pick, and E. Been, \u201cGait, balance and pos-\nture in major mental illnesses: Depression, anxiety and schizophrenia,\u201d\nAustin Med Sci , vol. 5, no. 1, Jan. 2020.\n[27] D. Kumar, D. J. Villarreal, and A. E. Meuret, \u201cWalking on the bright\nside: Associations between affect, depression, and gait,\u201d PLOS ONE ,\nvol. 16, no. 12, p. e0260893, Dec. 2021. [Online]. Available: https:\n//journals.plos.org/plosone/article?id=10.1371/journal.pone.0260893\n[28] K. M. Naugle, C. J. Hass, J. Joyner, S. A. Coombes, and C. M.\nJanelle, \u201cEmotional state affects the initiation of forward gait,\u201d\nEmotion , vol. 11, no. 2, p. 267\u2013277, Apr. 2011. [Online]. Available:\nhttps://ezproxy.lib.gla.ac.uk/login?url=https://search.ebscohost.com/\nlogin.aspx?direct=true&db=pdh&AN=2011-07236-007&site=ehost-live\n[29] M. Doumbia, M. Renard, L. Coudrat, and G. Bonnin, \u201cCharacterizing\nthe emotional context induced by music listening and its effects on gait\ninitiation: Exploiting physiological and biomechanical data,\u201d in Adjunct\nProceedings of the 31st ACM Conference on User Modeling, Adaptation\nand Personalization . Limassol Cyprus: ACM, Jun. 2023, p. 182\u2013186.\n[Online]. Available: https://dl.acm.org/doi/10.1145/3563359.3596982\n[30] A. D. Patel and J. R. Iversen, \u201cThe evolutionary neuroscience of\nmusical beat perception: the action simulation for auditory prediction\n(asap) hypothesis,\u201d Frontiers in Systems Neuroscience , vol. 8, 2014.\n[Online]. Available: https://www.frontiersin.org/articles/10.3389/fnsys.\n2014.00057\n[31] I. Domingos, G. Yang, and F. Deligianni, \u201cIntention detection of\ngait adaptation in natural settings,\u201d 2021 IEEE Symposium Series on\nComputational Intelligence (SSCI) , pp. 1\u20134, 2021.\n[32] F. Giorgi, D. Donati, and R. Tedeschi, \u201cCueing interventions for\ngait and balance in parkinson\u2019s disease: A scoping review of current\nevidence,\u201d Applied Sciences , vol. 14, no. 2424, p. 11781, Jan. 2024.\n[Online]. Available: https://www.mdpi.com/2076-3417/14/24/11781\n[33] P. Vuust, O. A. Heggli, K. J. Friston, and M. L. Kringelbach, \u201cMusic in\nthe brain,\u201d Nature reviews. Neuroscience , vol. 23, no. 5, pp. 287\u2013305,\n2022.\n[34] E. Large, \u201cOn synchronizing movement to music,\u201d Human Movement\nScience , vol. 19, pp. 527\u2013566, 2000.\n[35] E. Large and C. Palmer, \u201cPerceiving temporal regularity in music,\u201d\nCognitive Science , vol. 26, pp. 1\u201337, 2002.\n\n--- Page 12 ---\nJOURNAL OF XXXX, VOL. X, NO. X, XX XXXX 12\n[36] I. Hameed, D. M. Khan, S. M. Ahmed, S. S. Aftab, and H. Fazal,\n\u201cEnhancing motor imagery eeg signal decoding through machine\nlearning: A systematic review of recent progress,\u201d Computers in Biology\nand Medicine , vol. 185, p. 109534, Feb. 2025. [Online]. Available:\nhttps://www.sciencedirect.com/science/article/pii/S0010482524016196\n[37] K. K. Ang, Z. Y . Chin, H. Zhang, and C. Guan, \u201cFilter bank\ncommon spatial pattern (fbcsp) in brain-computer interface,\u201d in\n2008 IEEE International Joint Conference on Neural Networks\n(IEEE World Congress on Computational Intelligence) . Hong\nKong, China: IEEE, Jun. 2008, p. 2390\u20132397. [Online]. Available:\nhttp://ieeexplore.ieee.org/document/4634130/\n[38] B. Reuderink and M. Poel, \u201cRobustness of the common spatial patterns\nalgorithm in the bci-pipeline,\u201d IEEE Transactions on Circuits and\nSystems I-regular Papers - IEEE TRANS CIRCUIT SYST-I , 01 2008.\n[39] M. Grosse-Wentrup*, C. Liefhold, K. Gramann, and M. Buss,\n\u201cBeamforming in noninvasive brain\u2013computer interfaces,\u201d IEEE\nTransactions on Biomedical Engineering , vol. 56, no. 4, p. 1209\u20131219,\nApr. 2009. [Online]. Available: https://ieeexplore.ieee.org/document/\n4694120\n[40] A. Barachant, S. Bonnet, M. Congedo, and C. Jutten, \u201cMulticlass\nbrain\u2013computer interface classification by riemannian geometry,\u201d IEEE\nTransactions on Biomedical Engineering , vol. 59, no. 4, p. 920\u2013928,\nApr. 2012. [Online]. Available: https://ieeexplore.ieee.org/document/\n6046114\n[41] D. Wu, Y . Xu, and B.-L. Lu, \u201cTransfer learning for eeg-\nbased brain\u2013computer interfaces: A review of progress made since\n2016,\u201d IEEE Transactions on Cognitive and Developmental Systems ,\nvol. 14, no. 1, p. 4\u201319, Mar. 2022. [Online]. Available: https:\n//ieeexplore.ieee.org/document/9134411/\n[42] F. Zhuang, Z. Qi, K. Duan, D. Xi, Y . Zhu, H. Zhu, H. Xiong, and\nQ. He, \u201cA comprehensive survey on transfer learning,\u201d Proceedings of\nthe IEEE , vol. 109, no. 1, p. 43\u201376, Jan. 2021. [Online]. Available:\nhttps://ieeexplore.ieee.org/document/9134370/?arnumber=9134370\n[43] X. Huang, Y . Xu, J. Hua, W. Yi, H. Yin, R. Hu, and S. Wang,\n\u201cA review on signal processing approaches to reduce calibration time\nin eeg-based brain\u2013computer interface,\u201d Frontiers in Neuroscience ,\nvol. 15, Aug. 2021. [Online]. Available: https://www.frontiersin.org/\njournals/neuroscience/articles/10.3389/fnins.2021.733546/full\n[44] P. Zanini, M. Congedo, C. Jutten, S. Said, and Y . Berthoumieu, \u201cTransfer\nlearning: A riemannian geometry framework with applications to brain-\ncomputer interfaces,\u201d IEEE transactions on bio-medical engineering ,\nvol. 65, no. 5, p. 1107\u20131116, May 2018.\n[45] J. Wagner, R. Martines-Cancino, A. Delorme, S. Makeig, T. Solis-\nEscalante, C. Neuper, and G. Mueller-Putz, \u201cHigh-density eeg mobile\nbrain/body imaging data recorded during a challenging auditory gait\npacing task,\u201d Scientific Data , vol. 6, no. 211, pp. 1\u20139, 2019. [Online].\nAvailable: https://doi.org/10.1038/s41597-019-0223-2\n[46] O. Ledoit and M. Wolf, \u201cA well-conditioned estimator for large-\ndimensional covariance matrices,\u201d Journal of Multivariate Analysis ,\nvol. 88, no. 2, p. 365\u2013411, Feb. 2004. [Online]. Available:\nhttps://linkinghub.elsevier.com/retrieve/pii/S0047259X03000964\n[47] A. Barachant, Q. Barth \u00b4elemy, J.-R. King, A. Gramfort, S. Chevallier,\nP. L. C. Rodrigues, E. Olivetti, V . Goncharenko, G. W. vom Berg,\nG. Reguig, A. Lebeurrier, E. Bj \u00a8areholt, M. S. Yamamoto, P. Clisson, and\nM.-C. Corsi, \u201cpyriemann/pyriemann: v0.5,\u201d 2023. [Online]. Available:\nhttps://doi.org/10.5281/zenodo.8059038\n[48] M. Thaut, Rhythm, music, and the brain: Scientific foundations and\nclinical applications . Routledge, 2013.",
  "project_dir": "artifacts/projects/enhanced_cs.LG_2508.08216v1_Cross_Subject_and_Cross_Montage_EEG_Transfer_Learn",
  "communication_dir": "artifacts/projects/enhanced_cs.LG_2508.08216v1_Cross_Subject_and_Cross_Montage_EEG_Transfer_Learn/.agent_comm",
  "assigned_at": "2025-08-12T19:37:23.304651",
  "status": "assigned"
}